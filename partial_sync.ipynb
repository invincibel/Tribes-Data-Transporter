{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import nest_asyncio\n",
    "from gremlin_python.driver import client, serializer\n",
    "import sys\n",
    "import traceback\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime,date,timedelta\n",
    "import json\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "from gremlin_python.process.anonymous_traversal import traversal\n",
    "import re\n",
    "from collections import defaultdict \n",
    "from config import *\n",
    "\n",
    "nest_asyncio.apply()\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# DATE CONVERSION TO CHECK IF FILE DOWNLOADED IS DURING LAST 24 HRS\n",
    "def convert_date(_date):\n",
    "  return datetime.strptime(_date.strftime(date_format), date_format)\n",
    "\n",
    "# ADD VERTICES IN COSMOS DB VIA .submitAsync() callback()\n",
    "def insert_vertices(VERTIECS):\n",
    "  for vertex in VERTICES:\n",
    "      callback = gremlin_client.submitAsync(vertex)\n",
    "      if callback.result() is not None:\n",
    "          print(\"Inserted this vertex:\\n{0}\".format(callback.result().one()))\n",
    "      else:\n",
    "          print(\"Something went wrong with this query: {0}\".format(vertex))\n",
    "\n",
    "'''\n",
    "    ADD EDGES CONNECTING VERTICES WITH ID AS IDUNIQUE\n",
    "    GREMLIN QUERY : \n",
    "        g.V('IdUnique_From').addE('Type').to(g.V('IdUnique_To')).property(key,value)\n",
    "'''\n",
    "def insert_edges():\n",
    "    for _object in edge_jsonObject:\n",
    "      parts = []\n",
    "\n",
    "    #   PREPROCESS QUERY FOR ADDING KEY VALUE TO THE QUERY | .PROPERTY(KEY,VALUE)\n",
    "      for key, value in _object[\"Property\"].items():\n",
    "        part = \".property('\" + str(key) + \"','\" + str(value) + \"')\"\n",
    "        parts.append(part)\n",
    "\n",
    "      property_query = \"\".join(parts)\n",
    "\n",
    "    #   ITERATE OVER ALL THE VERTICES HAVING REQUIRED FROM/TO LABEL/IDOBJECT\n",
    "      for IdUnique_from in idof[_object[\"FromLabel\"]+_object[\"FromIdObject\"]]:\n",
    "        \n",
    "        for IdUnique_to in idof[_object[\"ToLabel\"]+_object[\"ToIdObject\"]]:\n",
    "  \n",
    "          #   CHECK FOR DeDuplication ONLY IF THERE IS AN EDGE \n",
    "          if str(IdUnique_from+IdUnique_to) in isedge :\n",
    "            \n",
    "            if _object[\"DeDuplication\"] == \"TRUE\":\n",
    "              continue\n",
    "            \n",
    "            else:\n",
    "              query = \"g.V('\" + IdUnique_from + \"').addE('\" + _object[\"Type\"] + \"').to(g.V('\" + IdUnique_to + \"'))\"\n",
    " \n",
    "              final_query = query + property_query\n",
    "              callback = gremlin_client.submitAsync(final_query)\n",
    " \n",
    "              if callback.result() is not None:\n",
    "                  print(\"Inserted this edge:\\n{0}\".format(callback.result().one()))\n",
    "              else:\n",
    "                  print(\"Something went wrong with this query:\\n{0}\".format(final_query))\n",
    "          \n",
    "          else:  \n",
    "            isedge[IdUnique_from+IdUnique_to] = True\n",
    "\n",
    "            query = \"g.V('\" + IdUnique_from + \"').addE('\" + _object[\"Type\"] + \"').to(g.V('\" + IdUnique_to + \"'))\"\n",
    "            \n",
    "            final_query = query + property_query\n",
    "            callback = gremlin_client.submitAsync(final_query)\n",
    "\n",
    "            if callback.result() is not None:\n",
    "                print(\"Inserted this edge:\\n{0}\".format(callback.result().one()))\n",
    "            else:\n",
    "                print(\"Something went wrong with this query:\\n{0}\".format(final_query))\n",
    "\n",
    "\n",
    "# ITERATE OVER JSON FILES TO ADD VERTICES AND EDGES\n",
    "def update_edges_and_vertices(fileName):\n",
    "  with open(fileName) as jsonFile:\n",
    "    jsonObject = json.load(jsonFile)\n",
    "    jsonFile.close()\n",
    "\n",
    "  for _object in jsonObject:\n",
    "            '''\n",
    "              INSERT VERTICES IN COSMOS DB \n",
    "              GREMLIN QUERY:\n",
    "                  g.V('IdUnique').property('id','IdUnique').property(key,value).property('pk','pk')\n",
    "            '''\n",
    "            if _object[\"Kind\"] == \"node\":\n",
    "                  parts = []\n",
    "                  \n",
    "                  part1 = \"g\"\n",
    "                  part2 = \".addV('\" + str(_object[\"IdUnique\"]) + \"')\"\n",
    "                  part3 = \".property('id','\" + str(_object[\"IdUnique\"]) + \"')\"\n",
    "                  parts.append(part1)\n",
    "                  parts.append(part2)\n",
    "                  parts.append(part3)\n",
    "                  \n",
    "                  for key, value in _object[\"Property\"].items():\n",
    "                          part4 = \".property('\" + str(key) + \"','\" + str(value) + \"')\"\n",
    "                          parts.append(part4)\n",
    "\n",
    "                  lastpart = \".property('pk', 'pk')\"\n",
    "                  parts.append(lastpart)\n",
    "\n",
    "                  query_insert_vertex = \"\".join(parts)\n",
    "                  \n",
    "                  VERTICES.append(query_insert_vertex)   \n",
    "\n",
    "                  # CREATE ADD IDUNIQUE IN HASH MAP TO ADD EDGES LATER\n",
    "                  for label in _object[\"Label\"]:\n",
    "                          idof[label + str(_object[\"Property\"][\"IdObject\"])].append(str(_object[\"IdUnique\"]))\n",
    "      \n",
    "          # ADD JSON OBJECTS INTO EDGES FOR PROESSING THEM INTO GREMLIN QUERIES IN INSERT_EDGES()\n",
    "            else:\n",
    "                  edge_jsonObject.append(_object)\n",
    "   \n",
    "\n",
    "# DOWNLOAD DATA FROM GCP\n",
    "def sync_files(bucket_name):\n",
    "  '''\n",
    "  TEMPERORARY MAKE DIRECTORY IN CWD TO STORE JSON FILES\n",
    "  DELETE ONCE PROCESSED\n",
    "  '''\n",
    "  makedir = cwd + \"\\\\graph-data/\"\n",
    "    \n",
    "  try:\n",
    "      os.mkdir(makedir)\n",
    "  except Exception:\n",
    "      pass\n",
    "    \n",
    "  storage_client = storage.Client()\n",
    "  blobs = storage_client.list_blobs(bucket_name)\n",
    "    \n",
    "  for blob in blobs:\n",
    "\n",
    "      if blob.name != \"graph-data/\":\n",
    "          \n",
    "          todays_date = convert_date(today)\n",
    "          date_created = convert_date(blob.time_created)\n",
    "          delta = todays_date - date_created \n",
    "          \n",
    "          destination_file_name = cwd + \"\\\\\" + blob.name\n",
    "          blob.download_to_filename(destination_file_name)\n",
    "          \n",
    "          '''\n",
    "            86400 SECONDS IN 24 HRS\n",
    "            UPDATE DATABASE WITH GIVEN JSON FILE\n",
    "            ONLY IF TIME DIFFERENCE IS <= 24 HRS  \n",
    "          '''\n",
    "          if(delta.total_seconds() <= 86400):\n",
    "\n",
    "              update_edges_and_vertices(destination_file_name)\n",
    "              insert_vertices(VERTICES)\n",
    "              insert_edges()\n",
    "\n",
    "              print(\"Database Updated Successfully\")\n",
    "          else:\n",
    "          #  files created before 24 hrs i.e. 86400 seconds are already there in the database\n",
    "              pass\n",
    "\n",
    "  # DELETE TEMPERARY CREATED DIRECTORY\n",
    "  shutil.rmtree(makedir)\n",
    "\n",
    "VERTICES = []\n",
    "edge_jsonObject = []\n",
    "\n",
    "gremlin_client = client.Client(\n",
    "        ENDPOINT , 'g',\n",
    "        username=\"/dbs/\" + DATABASE + \"/colls/\" + COLLECTION,\n",
    "        password=PRIMARY_KEY,\n",
    "        message_serializer=serializer.GraphSONSerializersV2d0()\n",
    ")\n",
    "g = traversal().withRemote(gremlin_client)\n",
    "\n",
    "\n",
    "# INITIALIZE CLIENT\n",
    "\n",
    "\n",
    "today = datetime.now()\n",
    "date_format = \"%m/%d/%Y, %H:%M:%S\"\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path_to_gcp_credentials\n",
    "# sync_files(BUCKET_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}